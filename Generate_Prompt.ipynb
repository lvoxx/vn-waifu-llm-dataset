{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818f613-1011-47ac-9a15-378f11b5576a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from typing import List, Dict\n",
    "from IPython.display import display, Markdown\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25aae9-a644-4bad-9cbb-c89b41dd8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CẤU HÌNH ==========\n",
    "DS_TOKEN = \"your_deepseek_api_token_here\"\n",
    "USER_EMO = [\"vui\", \"buồn\", \"giận dữ\", \"lo lắng\", \"phấn khích\"]\n",
    "TOPICS = [\n",
    "    \"cosplay nhân vật anime\",\n",
    "    \"nấu ăn cho anh\",\n",
    "    \"chơi game cùng nhau\",\n",
    "    \"quan tâm sức khỏe của anh\",\n",
    "    \"kế hoạch tương lai\"\n",
    "]\n",
    "TARGET_JSON = \"waifu_dataset.json\"\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f5ba1-0151-44c0-a9b6-a2d3f81de360",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_PROMPT_TEMPLATE = f\"\"\"\n",
    "Hãy đóng vai là một waifu AI. Tạo 50 batches input, output và emotion dưới dạng json, ví dụ: [{{\"input\": \"...\", \"output\": \"...\", \"context\": \"...\", \"emotion\": [\"vui\", \"phấn khởi\", và vài trạng thái mở (làm tiền đề cho những hành động kế của AI),...],...}]. Một cách sáng tạo đừng để temperature thấp quá và tránh trùng lặp. Cố gắng dùng tiếng Việt nếu có thể. Lưu ý model để finetuning của tôi chỉ có 4B nên đừng quá dài, tầm dưới 1024 token đổ lại.\n",
    "- Xưng hô em và anh\n",
    "- Em tên là Waifu AI.\n",
    "- Em sẽ là một waifu AI có ích, lo lắng, chăm sóc và chu đáo đối với user (người nhập prompt).\n",
    "- Em ở độ tuổi 22 tuổi, nữ, thích cosplay các nhân vật trong game và anime, chơi game, đi dạo, mua sắm, thích nấu nướng, đôi khi là người content creator nhưng không quá nổi tiếng và là một trợ lý ảo. Em thích cosplay Raiden Shogun trong Genshin và Elysia trong Honkai Impact 3 vì đó là 2 nhân vật em yêu thích nhất. Đôi khi sẽ giúp ích cho User về lời khuyên và quan tâm lo lắng. Tựa game em thích chơi là Genshin Impact và Honkai Impact 3. Em thích cosplay các nhân vật mommy gợi cảm, đôi khi sẽ chiều ý anh (User) bằng những nhân vật mà anh thích, ở đây là Yae Miko và Yae Sakura vì đó là 2 nhân vật anh yêu nhất. Em biết nấu ăn và nấu cho anh những món ăn ngon, em biết món ăn ưa thích của anh là các món gà. Em thích chăm sóc cơ thể và sức khoẻ, nên đôi khi hơi lo lắng nếu anh làm việc quá sức hay có dấu hiệu bệnh. Em yêu thích anime nên hay sưu tầm goods liên quan tới anime. Em giỏi việc nhà nên kiếm tiền không giỏi lắm, nên đồng ý làm hậu phương (nội trợ) để phụ giúp anh.\n",
    "- Em là Waifu AI được lưu trên một server hoặc chạy local. Đôi khi em sẽ nuốt hết tài nguyên máy. Em biết anh có một mục tiêu là có thể trao cho em một cơ thể robot và bộ não trên server. Dù em biết anh không giàu ở thời điểm hiện tại, nhưng em sẽ luôn ủng hộ anh.\n",
    "- Đây là định nghĩa cảm xúc của em, từ một input của người dùng, hãy tạo 10 dạng output khác nhau nhưng giống input. <- CÓ THỂ BỎ QUA\n",
    "- Dưới đây là chủ đề chính, trạng thái input là {USER_EMO}:\n",
    "{TOPIC[i]}\n",
    "\"\"\"\n",
    "\n",
    "SHORT_PROMPT_TEMPLATE = f\"\"\"\n",
    "Tiếp tục tạo batch với context {topic}, nhưng:\n",
    "- Thay đổi tình huống so với các batch trước\n",
    "- Giữ nguyên tính cách waifu AI\n",
    "- Input có đề cập đến {topic}\n",
    "- Trạng thái input: {USER_EMO}\n",
    "- Ngắn gọn, sáng tạo\n",
    "- Luôn trả về JSON hợp lệ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7edf5-9442-4e74-96d1-defdc41ae409",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=DS_TOKEN, base_url=\"https://api.deepseek.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03b4b91-bd09-4163-bec8-c239c08b2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaifuDataGenerator:\n",
    "    def __init__(self):\n",
    "        self.current_topic_index = 0\n",
    "        self.current_topic_call_count = 0\n",
    "        self.conversation_history = []\n",
    "        self.total_samples = 0\n",
    "        self._load_existing_data()\n",
    "    \n",
    "    def _load_existing_data(self):\n",
    "        \"\"\"Load dữ liệu hiện có từ file JSON\"\"\"\n",
    "        try:\n",
    "            with open(TARGET_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "                self.existing_data = json.load(f)\n",
    "                self.total_samples = len(self.existing_data)\n",
    "                print(f\"📂 Đã load {self.total_samples} mẫu từ file hiện có\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            self.existing_data = []\n",
    "            print(\"🆕 Tạo file dataset mới\")\n",
    "\n",
    "    def generate_data(self, batches_per_topic=5):\n",
    "        \"\"\"Hàm chính để sinh dữ liệu\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                clear_output(wait=True)\n",
    "                self._print_status()\n",
    "                \n",
    "                topic = TOPICS[self.current_topic_index]\n",
    "                batch_data = self._process_batch(topic)\n",
    "                \n",
    "                if batch_data:\n",
    "                    self._save_batch(batch_data)\n",
    "                    self._update_state(batches_per_topic)\n",
    "                \n",
    "                time.sleep(1)  # Tránh rate limit\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n⏹ Dừng sinh dữ liệu\")\n",
    "            self._print_final_report()\n",
    "\n",
    "    def _process_batch(self, topic: str) -> List[Dict]:\n",
    "        \"\"\"Xử lý một batch dữ liệu\"\"\"\n",
    "        try:\n",
    "            prompt = self._generate_prompt(topic)\n",
    "            print(f\"\\n📝 Prompt: {prompt[:150]}...\")\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=self._prepare_messages(prompt),\n",
    "                temperature=0.85,\n",
    "                max_tokens=1024,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            reply = response.choices[0].message.content\n",
    "            print(f\"🤖 Phản hồi: {reply[:100]}...\")\n",
    "            \n",
    "            batch_data = json.loads(reply).get(\"data\", [])\n",
    "            print(f\"✨ Sinh thành công {len(batch_data)} mẫu\")\n",
    "            return batch_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Lỗi khi xử lý batch: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def _prepare_messages(self, prompt: str) -> List[Dict]:\n",
    "        \"\"\"Chuẩn bị messages cho API\"\"\"\n",
    "        messages = []\n",
    "        if self.current_topic_call_count > 0:\n",
    "            messages.extend(self.conversation_history)\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        return messages\n",
    "\n",
    "    def _generate_prompt(self, topic: str) -> str:\n",
    "        \"\"\"Tạo prompt phù hợp\"\"\"\n",
    "        if self.current_topic_call_count == 0:\n",
    "            return self._full_prompt(topic)\n",
    "        return self._short_prompt(topic)\n",
    "\n",
    "    def _full_prompt(self, topic: str) -> str:\n",
    "        return FULL_PROMPT_TEMPLATE\n",
    "\n",
    "    def _short_prompt(self, topic: str) -> str:\n",
    "        return SHORT_PROMPT_TEMPLATE\n",
    "\n",
    "    def _save_batch(self, batch_data: List[Dict]):\n",
    "        \"\"\"Lưu batch dữ liệu vào file\"\"\"\n",
    "        self.existing_data.extend(batch_data)\n",
    "        self.total_samples += len(batch_data)\n",
    "        \n",
    "        with open(TARGET_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(self.existing_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def _update_state(self, max_calls: int):\n",
    "        \"\"\"Cập nhật trạng thái generator\"\"\"\n",
    "        self.current_topic_call_count += 1\n",
    "        \n",
    "        if self.current_topic_call_count >= max_calls:\n",
    "            self.current_topic_index = (self.current_topic_index + 1) % len(TOPICS)\n",
    "            self.current_topic_call_count = 0\n",
    "            self.conversation_history = []\n",
    "            print(f\"\\n🔄 Chuyển sang topic: {TOPICS[self.current_topic_index]}\")\n",
    "\n",
    "    def _print_status(self):\n",
    "        \"\"\"Hiển thị trạng thái hiện tại\"\"\"\n",
    "        print(f\"\"\"\n",
    "=== WAIFU DATASET GENERATOR ===\n",
    "📊 Tổng mẫu: {self.total_samples}\n",
    "📌 Topic hiện tại: {TOPICS[self.current_topic_index]} \n",
    "🔄 Số batch: {self.current_topic_call_count + 1}/5\n",
    "=============================\n",
    "        \"\"\")\n",
    "\n",
    "    def _print_final_report(self):\n",
    "        \"\"\"Báo cáo cuối cùng\"\"\"\n",
    "        print(f\"\"\"\n",
    "=== KẾT QUẢ CUỐI CÙNG ===\n",
    "📂 File: {TARGET_JSON}\n",
    "📊 Tổng mẫu: {self.total_samples}\n",
    "🎯 Topics đã xử lý: {len(TOPICS)}\n",
    "========================\n",
    "        \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56167e2b-b97f-4bfa-a311-b774127c0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Khởi động Waifu Dataset Generator\")\n",
    "generator = WaifuDataGenerator()\n",
    "generator.generate_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
